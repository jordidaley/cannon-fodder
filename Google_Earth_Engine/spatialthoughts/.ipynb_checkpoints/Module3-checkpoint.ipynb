{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef5a3d0-31af-4412-bd2e-db9388af2968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import collections\n",
    "collections.Callable = collections.abc.Callable\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3177acad-cb80-462b-a8a0-8697d3535ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82203b6243b45158482e45b364c4256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "bangalore = ee.FeatureCollection(\"users/ujavalgandhi/public/bangalore_boundary\")\n",
    "s2 = ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
    "# The following collections were created using the\n",
    "# Drawing Tools in the code editor\n",
    "urban = ee.FeatureCollection(\"users/ujavalgandhi/e2e/urban_gcps\")\n",
    "bare = ee.FeatureCollection(\"users/ujavalgandhi/e2e/bare_gcps\")\n",
    "water = ee.FeatureCollection(\"users/ujavalgandhi/e2e/water_gcps\")\n",
    "vegetation = ee.FeatureCollection(\"users/ujavalgandhi/e2e/vegetation_gcps\")\n",
    "\n",
    "filtered = s2 \\\n",
    ".filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\\n",
    "  .filter(ee.Filter.date('2019-01-01', '2020-01-01')) \\\n",
    "  .filter(ee.Filter.bounds(bangalore)) \\\n",
    "  .select('B.*')\n",
    "\n",
    "composite = filtered.median().clip(bangalore)\n",
    "\n",
    "# Display the input composite.\n",
    "rgbVis = {\n",
    "  'min': 0.0,\n",
    "  'max': 3000,\n",
    "  'bands': ['B4', 'B3', 'B2'],\n",
    "}\n",
    "Map.addLayer(composite, rgbVis, 'image')\n",
    "\n",
    "gcps = urban.merge(bare).merge(water).merge(vegetation)\n",
    "\n",
    "# Overlay the point on the image to get training data.\n",
    "training = composite.sampleRegions(\n",
    "  collection=gcps, properties=['landcover'], scale=10)\n",
    "\n",
    "# Train a classifier.\n",
    "classifier = ee.Classifier.smileRandomForest(50).train(\n",
    "  features=training, classProperty='landcover', inputProperties=composite.bandNames())\n",
    "\n",
    "# # Classify the image.\n",
    "classified = composite.classify(classifier)\n",
    "Map.addLayer(classified, {'min': 0, 'max': 3, 'palette': ['gray', 'brown', 'blue', 'green']}, '2019')\n",
    "\n",
    "# Display the GCPs\n",
    "# We use the style() function to style the GCPs\n",
    "palette = ee.List(['gray','brown','blue','green'])\n",
    "landcover = ee.List([0, 1, 2, 3])\n",
    "\n",
    "def funclc(lc):\n",
    "    color = palette.get(landcover.indexOf(lc))\n",
    "    markerStyle = {'color': 'white', 'pointShape': 'diamond', \\\n",
    "        'pointSize': 4, 'width': 1, 'fillColor': color}\n",
    "    def funcp(point):\n",
    "        return point.set('style', markerStyle)\n",
    "    return gcps.filter(ee.Filter.eq('landcover', lc)) \\\n",
    "        .map(funcp)\n",
    "    \n",
    "gcpsStyled = ee.FeatureCollection(\n",
    "    landcover.map(funclc)).flatten()\n",
    "\n",
    "gcpsStyling = gcpsStyled.style(\n",
    "    styleProperty='style')\n",
    "\n",
    "Map.addLayer(gcpsStyling, {}, 'GCPs')\n",
    "Map.centerObject(gcpsStyled)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48e14e5d-5769-41fd-82b0-930c104c8973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1da1ebb006047bcae82a5ee4946b122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "s2 = ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
    "urbanAreas = ee.FeatureCollection(\"users/jordandaleyco/ne_10m_urban_areas\")\n",
    "\n",
    "# Perform supervised classification for your city\n",
    "# Find the feature id by adding the layer to the map and using Inspector.\n",
    "city = urbanAreas.filter(ee.Filter.eq('system:index', '00000000000000002397'))\n",
    "geometry = city.geometry()\n",
    "Map.centerObject(geometry)\n",
    "\n",
    "filtered = s2 \\\n",
    ".filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\\n",
    "  .filter(ee.Filter.date('2019-01-01', '2020-01-01')) \\\n",
    "  .filter(ee.Filter.bounds(geometry)) \\\n",
    "  .select('B.*')\n",
    "\n",
    "composite = filtered.median().clip(geometry)\n",
    "\n",
    "# Display the input composite.\n",
    "\n",
    "rgbVis = {'min': 0.0, 'max': 3000, 'bands': ['B4', 'B3', 'B2']}\n",
    "Map.addLayer(composite, rgbVis, 'image')\n",
    "\n",
    "# Exercise\n",
    "# Add training points for 4 classes\n",
    "# Assign the 'landcover' property as follows\n",
    "\n",
    "# urban: 0\n",
    "# bare: 1\n",
    "# water: 2\n",
    "# vegetation: 3\n",
    "\n",
    "urban = ee.FeatureCollection(\"users/jordandaleyco/urban_pts\")\n",
    "bare = ee.FeatureCollection(\"users/jordandaleyco/bare_pts\")\n",
    "water = ee.FeatureCollection(\"users/jordandaleyco/water_pts\")\n",
    "vegetation = ee.FeatureCollection(\"users/jordandaleyco/veg_pts\")\n",
    "\n",
    "# After adding points, uncomments lines below\n",
    "\n",
    "gcps = urban.merge(bare).merge(water).merge(vegetation)\n",
    "\n",
    "# # Overlay the point on the image to get training data.\n",
    "\n",
    "training = composite.sampleRegions(\n",
    "  collection=gcps, properties=['landcover'], scale=10, tileScale=16)\n",
    "\n",
    "\n",
    "# Train a classifier.\n",
    "classifier = ee.Classifier.smileRandomForest(50).train(\n",
    "  features=training, classProperty='landcover', inputProperties=composite.bandNames())\n",
    "\n",
    "# # Classify the image.\n",
    "classified = composite.classify(classifier)\n",
    "Map.addLayer(classified, {'min': 0, 'max': 3, 'palette': ['gray', 'brown', 'blue', 'green']}, '2019')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70abaa3c-931e-422d-b60d-41010674d0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[41, 4, 0, 0], [3, 43, 0, 0], [0, 0, 48, 3], [0, 0, 0, 37]]\n",
      "Test Accuracy 0.9441340782122905\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60a821cd1b747bd94529c86483c6b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "s2 = ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
    "basin = ee.FeatureCollection(\"WWF/HydroSHEDS/v1/Basins/hybas_7\")\n",
    "gcp = ee.FeatureCollection(\"users/ujavalgandhi/e2e/arkavathy_gcps\")\n",
    "\n",
    "arkavathy = basin.filter(ee.Filter.eq('HYBAS_ID', 4071139640))\n",
    "boundary = arkavathy.geometry()\n",
    "rgbVis = {\n",
    "  'min': 0.0,\n",
    "  'max': 3000,\n",
    "  'bands': ['B4', 'B3', 'B2'],\n",
    "}\n",
    "\n",
    "filtered = s2 \\\n",
    ".filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\\n",
    "  .filter(ee.Filter.date('2019-01-01', '2020-01-01')) \\\n",
    "  .filter(ee.Filter.bounds(boundary)) \\\n",
    "  .select('B.*')\n",
    "\n",
    "composite = filtered.median().clip(boundary)\n",
    "\n",
    "# Display the input composite.\n",
    "Map.addLayer(composite, rgbVis, 'image')\n",
    "\n",
    "# Add a random column and split the GCPs into training and validation set\n",
    "gcp = gcp.randomColumn()\n",
    "\n",
    "# This being a simpler classification, we take 60% points\n",
    "# for validation. Normal recommended ratio is\n",
    "# 70% training, 30% validation\n",
    "trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6))\n",
    "validationGcp = gcp.filter(ee.Filter.gte('random', 0.6))\n",
    "\n",
    "# Overlay the point on the image to get training data.\n",
    "training = composite.sampleRegions(\n",
    "  collection=trainingGcp, properties=['landcover'], scale=10, tileScale=16)\n",
    "\n",
    "\n",
    "# Train a classifier.\n",
    "classifier = ee.Classifier.smileRandomForest(50).train(\n",
    "  features=training, classProperty='landcover', inputProperties=composite.bandNames())\n",
    "\n",
    "# # Classify the image.\n",
    "classified = composite.classify(classifier)\n",
    "Map.addLayer(classified, {'min': 0, 'max': 3, 'palette': ['gray', 'brown', 'blue', 'green']}, '2019')\n",
    "\n",
    "#**************************************************************************\n",
    "# Accuracy Assessment\n",
    "#**************************************************************************\n",
    "\n",
    "# Use classification map to assess accuracy using the validation fraction\n",
    "# of the overall training set created above.\n",
    "test = classified.sampleRegions(\n",
    "  collection=validationGcp, properties=['landcover'], scale=10, tileScale=16)\n",
    "\n",
    "testConfusionMatrix = test.errorMatrix('landcover', 'classification')\n",
    "# Printing of confusion matrix may time out. Alternatively, you can export it as CSV\n",
    "print('Confusion Matrix', testConfusionMatrix.getInfo())\n",
    "print('Test Accuracy', testConfusionMatrix.accuracy().getInfo())\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92f42a73-5c9c-432f-a69e-43153e8dcdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[41, 4, 0, 0], [3, 43, 0, 0], [0, 0, 48, 3], [0, 0, 0, 37]]\n",
      "Test Accuracy 0.9441340782122905\n",
      "Producer's Accuracy [[0.9111111111111111], [0.9347826086956522], [0.9411764705882353], [1]]\n",
      "Consumer's Accuracy [[0.9318181818181818, 0.9148936170212766, 1, 0.925]]\n",
      "Kappa Coefficient 0.9253264361102999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc9814c9a2a4d1b82a505da2b3ebdc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "classified = ee.Image('users/ujavalgandhi/e2e/arkavathy_base_classification')\n",
    "gcp = ee.FeatureCollection('users/ujavalgandhi/e2e/arkavathy_gcps')\n",
    "gcp = gcp.randomColumn()\n",
    "\n",
    "trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6))\n",
    "validationGcp = gcp.filter(ee.Filter.gte('random', 0.6))\n",
    "\n",
    "#**************************************************************************\n",
    "# Accuracy Assessment\n",
    "#**************************************************************************\n",
    "\n",
    "# Use classification map to assess accuracy using the validation fraction\n",
    "# of the overall training set created above.\n",
    "test = classified.sampleRegions(\n",
    "  collection=validationGcp, properties=['landcover'], scale=10, tileScale=16)\n",
    "\n",
    "testConfusionMatrix = test.errorMatrix('landcover', 'classification')\n",
    "print('Confusion Matrix', testConfusionMatrix.getInfo())\n",
    "print('Test Accuracy', testConfusionMatrix.accuracy().getInfo())\n",
    "\n",
    "# Exercise\n",
    "\n",
    "# Calculate and print the following assessment metrics\n",
    "# 1. Producer's accuracy\n",
    "# 2. Consumer's accuracy\n",
    "# 3. Kappa coefficient\n",
    "\n",
    "print(\"Producer's Accuracy\", testConfusionMatrix.producersAccuracy().getInfo())\n",
    "print(\"Consumer's Accuracy\", testConfusionMatrix.consumersAccuracy().getInfo())\n",
    "print('Kappa Coefficient', testConfusionMatrix.kappa().getInfo())\n",
    "\n",
    "# Hint: Look at the ee.ConfusionMatrix module for appropriate methods\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "badf9852-f17d-4a4b-8354-6270978286d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[41, 3, 0, 0], [3, 43, 0, 0], [0, 0, 49, 2], [0, 0, 0, 37]]\n",
      "Test Accuracy 0.9550561797752809\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ba539e472749e29f1396f644aa3dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "s2 = ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
    "basin = ee.FeatureCollection(\"WWF/HydroSHEDS/v1/Basins/hybas_7\")\n",
    "gcp = ee.FeatureCollection(\"users/ujavalgandhi/e2e/arkavathy_gcps\")\n",
    "alos = ee.Image(\"JAXA/ALOS/AW3D30/V2_2\")\n",
    "\n",
    "arkavathy = basin.filter(ee.Filter.eq('HYBAS_ID', 4071139640))\n",
    "boundary = arkavathy.geometry()\n",
    "rgbVis = {\n",
    "  'min': 0.0,\n",
    "  'max': 3000,\n",
    "  'bands': ['B4', 'B3', 'B2'],\n",
    "}\n",
    "# Function to remove cloud and snow pixels from Sentinel-2 SR image\n",
    "\n",
    "def maskCloudAndShadowsSR(image):\n",
    "    cloudProb = image.select('MSK_CLDPRB')\n",
    "    snowProb = image.select('MSK_SNWPRB')\n",
    "    cloud = cloudProb.lt(10)\n",
    "    scl = image.select('SCL')\n",
    "    shadow = scl.eq(3); # 3 = cloud shadow\n",
    "    cirrus = scl.eq(10); # 10 = cirrus\n",
    "    # Cloud probability less than 10% or cloud shadow classification\n",
    "    mask = cloud.And(cirrus.neq(1)).And(shadow.neq(1))\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "filtered = s2 \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\\n",
    "    .filter(ee.Filter.date('2019-01-01', '2020-01-01')) \\\n",
    "    .filter(ee.Filter.bounds(boundary)) \\\n",
    "    .map(maskCloudAndShadowsSR) \\\n",
    "    .select('B.*')\n",
    "\n",
    "composite = filtered.median().clip(boundary)\n",
    "\n",
    "def addIndices(image):\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename(['ndvi'])\n",
    "    ndbi = image.normalizedDifference(['B11', 'B8']).rename(['ndbi'])\n",
    "    mndwi = image.normalizedDifference(['B3', 'B11']).rename(['mndwi'])\n",
    "    bsi = image.expression(\n",
    "      '(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) ', {\n",
    "        'X': image.select('B11'), #swir1\n",
    "        'Y': image.select('B4'),  #red\n",
    "        'A': image.select('B8'), # nir\n",
    "        'B': image.select('B2'), # blue\n",
    "    }).rename('bsi')\n",
    "    return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi)\n",
    "\n",
    "composite = addIndices(composite)\n",
    "\n",
    "# Calculate Slope and Elevation\n",
    "elev = alos.select('AVE_DSM').rename('elev')\n",
    "slope = ee.Terrain.slope(alos.select('AVE_DSM')).rename('slope')\n",
    "\n",
    "composite = composite.addBands(elev).addBands(slope)\n",
    "\n",
    "visParams = {'bands': ['B4',  'B3',  'B2'], 'min': 0, 'max': 3000, 'gamma': 1.2}\n",
    "Map.addLayer(composite, visParams, 'RGB')\n",
    "\n",
    "# Normalize the image\n",
    "\n",
    "# Machine learning algorithms work best on images when all features have\n",
    "# the same range\n",
    "\n",
    "# Function to Normalize Image\n",
    "# Pixel Values should be between 0 and 1\n",
    "# Formula is (x - xmin) / (xmax - xmin)\n",
    "#**************************************************************************\n",
    "def normalize(image):\n",
    "    bandNames = image.bandNames()\n",
    "    # Compute min and max of the image\n",
    "    minDict = image.reduceRegion(\n",
    "        reducer=ee.Reducer.min(),\n",
    "        geometry=boundary,\n",
    "        scale=20,\n",
    "        maxPixels=1e9,\n",
    "        bestEffort=True,\n",
    "        tileScale=16\n",
    "    )\n",
    "    maxDict = image.reduceRegion(\n",
    "        reducer=ee.Reducer.max(),\n",
    "        geometry=boundary,\n",
    "        scale=20,\n",
    "        maxPixels=1e9,\n",
    "        bestEffort=True,\n",
    "        tileScale=16\n",
    "    )\n",
    "    mins = ee.Image.constant(minDict.values(bandNames))\n",
    "    maxs = ee.Image.constant(maxDict.values(bandNames))\n",
    "\n",
    "    normalized = image.subtract(mins).divide(maxs.subtract(mins))\n",
    "    return normalized\n",
    "\n",
    "composite = normalize(composite)\n",
    "# Add a random column and split the GCPs into training and validation set\n",
    "gcp = gcp.randomColumn()\n",
    "\n",
    "# This being a simpler classification, we take 60% points\n",
    "# for validation. Normal recommended ratio is\n",
    "# 70% training, 30% validation\n",
    "trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6))\n",
    "validationGcp = gcp.filter(ee.Filter.gte('random', 0.6))\n",
    "\n",
    "# Overlay the point on the image to get training data.\n",
    "\n",
    "training = composite.sampleRegions(\n",
    "  collection=trainingGcp, properties=['landcover'], scale=10, tileScale=16)\n",
    "print(training.getInfo())\n",
    "# Train a classifier.\n",
    "\n",
    "classifier = ee.Classifier.smileRandomForest(50).train(\n",
    "  features=training, classProperty='landcover', inputProperties=composite.bandNames())\n",
    "\n",
    "# Classify the image.\n",
    "classified = composite.classify(classifier)\n",
    "\n",
    "Map.addLayer(classified, {'min': 0, 'max': 3, 'palette': ['gray', 'brown', 'blue', 'green']}, '2019')\n",
    "\n",
    "#**************************************************************************\n",
    "# Accuracy Assessment\n",
    "#**************************************************************************\n",
    "\n",
    "# Use classification map to assess accuracy using the validation fraction\n",
    "# of the overall training set created above.\n",
    "test = classified.sampleRegions(\n",
    "  collection=validationGcp, properties=['landcover'], scale=10, tileScale=16)\n",
    "\n",
    "testConfusionMatrix = test.errorMatrix('landcover', 'classification')\n",
    "# Printing of confusion matrix may time out. Alternatively, you can export it as CSV\n",
    "print('Confusion Matrix', testConfusionMatrix.getInfo())\n",
    "print('Test Accuracy', testConfusionMatrix.accuracy().getInfo())\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad6cf5bc-5c65-4f19-8ca2-97ed70277be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[2, 0, 0], [0, 2, 0], [0, 0, 4]]\n",
      "Test Accuracy 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e190e3e80b6c4cbcb0711018ae2040db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise\n",
    "\n",
    "# Improve your classification from Exercise 01c\n",
    "\n",
    "Map = geemap.Map()\n",
    "\n",
    "s2 = ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
    "urbanAreas = ee.FeatureCollection(\"users/jordandaleyco/ne_10m_urban_areas\")\n",
    "\n",
    "# Perform supervised classification for your city\n",
    "# Find the feature id by adding the layer to the map and using Inspector.\n",
    "city = urbanAreas.filter(ee.Filter.eq('system:index', '00000000000000002397'))\n",
    "geometry = city.geometry()\n",
    "Map.centerObject(geometry)\n",
    "\n",
    "def maskCloudAndShadowsSR(image):\n",
    "    cloudProb = image.select('MSK_CLDPRB')\n",
    "    snowProb = image.select('MSK_SNWPRB')\n",
    "    cloud = cloudProb.lt(30)\n",
    "    scl = image.select('SCL')\n",
    "    shadow = scl.eq(3); # 3 = cloud shadow\n",
    "    cirrus = scl.eq(15); # 10 = cirrus\n",
    "    # Cloud probability less than 10% or cloud shadow classification\n",
    "    mask = cloud.And(cirrus.neq(1)).And(shadow.neq(1))\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "filtered = s2 \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\\n",
    "    .filter(ee.Filter.date('2019-01-01', '2020-01-01')) \\\n",
    "    .filter(ee.Filter.bounds(geometry)) \\\n",
    "    .map(maskCloudAndShadowsSR) \\\n",
    "    .select('B.*')\n",
    "\n",
    "composite = filtered.median().clip(geometry)\n",
    "\n",
    "def addIndices(image):\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename(['ndvi'])\n",
    "    ndbi = image.normalizedDifference(['B11', 'B8']).rename(['ndbi'])\n",
    "    mndwi = image.normalizedDifference(['B3', 'B11']).rename(['mndwi'])\n",
    "    bsi = image.expression(\n",
    "      '(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) ', {\n",
    "        'X': image.select('B11'), #swir1\n",
    "        'Y': image.select('B4'),  #red\n",
    "        'A': image.select('B8'), # nir\n",
    "        'B': image.select('B2'), # blue\n",
    "    }).rename('bsi')\n",
    "    return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi)\n",
    "\n",
    "composite = addIndices(composite)\n",
    "\n",
    "# Calculate Slope and Elevation\n",
    "elev = alos.select('AVE_DSM').rename('elev')\n",
    "slope = ee.Terrain.slope(alos.select('AVE_DSM')).rename('slope')\n",
    "\n",
    "composite = composite.addBands(elev).addBands(slope)\n",
    "\n",
    "visParams = {'bands': ['B4',  'B3',  'B2'], 'min': 0, 'max': 3000, 'gamma': 1.2}\n",
    "Map.addLayer(composite, visParams, 'RGB')\n",
    "\n",
    "# Exercise\n",
    "# Add training points for 4 classes\n",
    "# Assign the 'landcover' property as follows\n",
    "\n",
    "# urban: 0\n",
    "# bare: 1\n",
    "# water: 2\n",
    "# vegetation: 3\n",
    "\n",
    "urban = ee.FeatureCollection(\"users/jordandaleyco/urban_pts\")\n",
    "bare = ee.FeatureCollection(\"users/jordandaleyco/bare_pts\")\n",
    "water = ee.FeatureCollection(\"users/jordandaleyco/water_pts\")\n",
    "vegetation = ee.FeatureCollection(\"users/jordandaleyco/veg_pts\")\n",
    "\n",
    "# Normalize the image\n",
    "\n",
    "# Machine learning algorithms work best on images when all features have\n",
    "# the same range\n",
    "\n",
    "# Function to Normalize Image\n",
    "# Pixel Values should be between 0 and 1\n",
    "# Formula is (x - xmin) / (xmax - xmin)\n",
    "#**************************************************************************\n",
    "def normalize(image):\n",
    "    bandNames = image.bandNames()\n",
    "    # Compute min and max of the image\n",
    "    minDict = image.reduceRegion(\n",
    "        reducer=ee.Reducer.min(),\n",
    "        geometry=geometry,\n",
    "        scale=20,\n",
    "        maxPixels=1e9,\n",
    "        bestEffort=True,\n",
    "        tileScale=16\n",
    "    )\n",
    "    maxDict = image.reduceRegion(\n",
    "        reducer=ee.Reducer.max(),\n",
    "        geometry=geometry,\n",
    "        scale=20,\n",
    "        maxPixels=1e9,\n",
    "        bestEffort=True,\n",
    "        tileScale=16\n",
    "    )\n",
    "    mins = ee.Image.constant(minDict.values(bandNames))\n",
    "    maxs = ee.Image.constant(maxDict.values(bandNames))\n",
    "\n",
    "    normalized = image.subtract(mins).divide(maxs.subtract(mins))\n",
    "    return normalized\n",
    "\n",
    "composite = normalize(composite)\n",
    "\n",
    "gcps = urban.merge(bare).merge(water).merge(vegetation)\n",
    "\n",
    "# Add a random column and split the GCPs into training and validation set\n",
    "gcp = gcps.randomColumn()\n",
    "\n",
    "# This being a simpler classification, we take 60% points\n",
    "# for validation. Normal recommended ratio is\n",
    "# 70% training, 30% validation\n",
    "trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6))\n",
    "validationGcp = gcp.filter(ee.Filter.gte('random', 0.6))\n",
    "\n",
    "# Overlay the point on the image to get training data.\n",
    "\n",
    "training = composite.sampleRegions(\n",
    "  collection=trainingGcp, properties=['landcover'], scale=10, tileScale=16)\n",
    "\n",
    "# Train a classifier.\n",
    "\n",
    "classifier = ee.Classifier.smileRandomForest(50).train(\n",
    "  features=training, classProperty='landcover', inputProperties=composite.bandNames())\n",
    "\n",
    "# Classify the image.\n",
    "classified = composite.classify(classifier)\n",
    "\n",
    "Map.addLayer(classified, {'min': 0, 'max': 3, 'palette': ['gray', 'brown', 'blue', 'green']}, '2019')\n",
    "\n",
    "#**************************************************************************\n",
    "# Accuracy Assessment\n",
    "#**************************************************************************\n",
    "\n",
    "# Use classification map to assess accuracy using the validation fraction\n",
    "# of the overall training set created above.\n",
    "test = classified.sampleRegions(\n",
    "  collection=validationGcp, properties=['landcover'], scale=10, tileScale=16)\n",
    "\n",
    "testConfusionMatrix = test.errorMatrix('landcover', 'classification')\n",
    "# Printing of confusion matrix may time out. Alternatively, you can export it as CSV\n",
    "print('Confusion Matrix', testConfusionMatrix.getInfo())\n",
    "print('Test Accuracy', testConfusionMatrix.accuracy().getInfo())\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "779a8db4-9c19-49d9-894d-49c45181307a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'FeatureCollection', 'columns': {'accuracy': 'Float', 'matrix': 'Integer<dimensions=2>', 'system:index': 'String'}, 'features': [{'type': 'Feature', 'geometry': None, 'id': '0', 'properties': {'accuracy': 0.949438202247191, 'matrix': [[41, 3, 0, 0], [3, 43, 0, 0], [0, 0, 48, 3], [0, 0, 0, 37]]}}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4202f6ff0386412aab5d328ac539f66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "s2 = ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
    "basin = ee.FeatureCollection(\"WWF/HydroSHEDS/v1/Basins/hybas_7\")\n",
    "gcp = ee.FeatureCollection(\"users/ujavalgandhi/e2e/arkavathy_gcps\")\n",
    "alos = ee.Image(\"JAXA/ALOS/AW3D30/V2_2\")\n",
    "\n",
    "arkavathy = basin.filter(ee.Filter.eq('HYBAS_ID', 4071139640))\n",
    "boundary = arkavathy.geometry()\n",
    "rgbVis = {\n",
    "  'min': 0.0,\n",
    "  'max': 3000,\n",
    "  'bands': ['B4', 'B3', 'B2'],\n",
    "}\n",
    "# Function to remove cloud and snow pixels from Sentinel-2 SR image\n",
    "\n",
    "def maskCloudAndShadowsSR(image):\n",
    "    cloudProb = image.select('MSK_CLDPRB')\n",
    "    snowProb = image.select('MSK_SNWPRB')\n",
    "    cloud = cloudProb.lt(10)\n",
    "    scl = image.select('SCL')\n",
    "    shadow = scl.eq(3); # 3 = cloud shadow\n",
    "    cirrus = scl.eq(10); # 10 = cirrus\n",
    "    # Cloud probability less than 10% or cloud shadow classification\n",
    "    mask = cloud.And(cirrus.neq(1)).And(shadow.neq(1))\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "filtered = s2 \\\n",
    ".filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\\n",
    "  .filter(ee.Filter.date('2019-01-01', '2020-01-01')) \\\n",
    "  .filter(ee.Filter.bounds(boundary)) \\\n",
    "  .map(maskCloudAndShadowsSR) \\\n",
    "  .select('B.*')\n",
    "\n",
    "composite = filtered.median().clip(boundary)\n",
    "\n",
    "def addIndices(image):\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename(['ndvi'])\n",
    "    ndbi = image.normalizedDifference(['B11', 'B8']).rename(['ndbi'])\n",
    "    mndwi = image.normalizedDifference(['B3', 'B11']).rename(['mndwi'])\n",
    "    bsi = image.expression(\n",
    "      '(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) ', {\n",
    "        'X': image.select('B11'), #swir1\n",
    "        'Y': image.select('B4'),  #red\n",
    "        'A': image.select('B8'), # nir\n",
    "        'B': image.select('B2'), # blue\n",
    "    }).rename('bsi')\n",
    "    return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi)\n",
    "\n",
    "composite = addIndices(composite)\n",
    "\n",
    "visParams = {'bands': ['B4',  'B3',  'B2'], 'min': 0, 'max': 3000, 'gamma': 1.2}\n",
    "Map.addLayer(composite, visParams, 'RGB')\n",
    "\n",
    "# Normalize the image\n",
    "\n",
    "# Machine learning algorithms work best on images when all features have\n",
    "# the same range\n",
    "\n",
    "# Function to Normalize Image\n",
    "# Pixel Values should be between 0 and 1\n",
    "# Formula is (x - xmin) / (xmax - xmin)\n",
    "#**************************************************************************\n",
    "def normalize(image):\n",
    "    bandNames = image.bandNames()\n",
    "    # Compute min and max of the image\n",
    "    minDict = image.reduceRegion(\n",
    "        reducer=ee.Reducer.min(),\n",
    "        geometry=boundary,\n",
    "        scale=20,\n",
    "        maxPixels=1e9,\n",
    "        bestEffort=True,\n",
    "        tileScale=16\n",
    "    )\n",
    "    maxDict = image.reduceRegion(\n",
    "        reducer=ee.Reducer.max(),\n",
    "        geometry=boundary,\n",
    "        scale=20,\n",
    "        maxPixels=1e9,\n",
    "        bestEffort=True,\n",
    "        tileScale=16\n",
    "    )\n",
    "    mins = ee.Image.constant(minDict.values(bandNames))\n",
    "    maxs = ee.Image.constant(maxDict.values(bandNames))\n",
    "\n",
    "    normalized = image.subtract(mins).divide(maxs.subtract(mins))\n",
    "    return normalized\n",
    "\n",
    "composite = normalize(composite)\n",
    "# Add a random column and split the GCPs into training and validation set\n",
    "gcp = gcp.randomColumn()\n",
    "\n",
    "# This being a simpler classification, we take 60% points\n",
    "# for validation. Normal recommended ratio is\n",
    "# 70% training, 30% validation\n",
    "trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6))\n",
    "validationGcp = gcp.filter(ee.Filter.gte('random', 0.6))\n",
    "Map.addLayer(validationGcp)\n",
    "# Overlay the point on the image to get training data.\n",
    "training = composite.sampleRegions(\n",
    "  collection=trainingGcp, properties=['landcover'], scale=10, tileScale=16)\n",
    "\n",
    "# Train a classifier.\n",
    "\n",
    "classifier = ee.Classifier.smileRandomForest(50).train(\n",
    "  features=training, classProperty='landcover', inputProperties=composite.bandNames())\n",
    "\n",
    "# Classify the image.\n",
    "classified = composite.classify(classifier)\n",
    "\n",
    "Map.addLayer(classified, {'min': 0, 'max': 3, 'palette': ['gray', 'brown', 'blue', 'green']}, '2019')\n",
    "\n",
    "#**************************************************************************\n",
    "# Accuracy Assessment\n",
    "#**************************************************************************\n",
    "\n",
    "# Use classification map to assess accuracy using the validation fraction\n",
    "# of the overall training set created above.\n",
    "test = classified.sampleRegions(\n",
    "  collection=validationGcp, properties=['landcover'], scale=10, tileScale=16)\n",
    "\n",
    "testConfusionMatrix = test.errorMatrix('landcover', 'classification')\n",
    "print('Confusion Matrix', testConfusionMatrix)\n",
    "print('Test Accuracy', testConfusionMatrix.accuracy())\n",
    "\n",
    "#**************************************************************************\n",
    "# Exporting Results\n",
    "#**************************************************************************\n",
    "\n",
    "# Create a Feature with None geometry and the value we want to export.\n",
    "# Use .array() to convert Confusion Matrix to an Array so it can be\n",
    "# exported in a CSV file\n",
    "fc = ee.FeatureCollection([\n",
    "  ee.Feature(None, {\n",
    "    'accuracy': testConfusionMatrix.accuracy(),\n",
    "    'matrix': testConfusionMatrix.array()\n",
    "  })\n",
    "  ])\n",
    "print(fc.getInfo())\n",
    "\n",
    "myTask = ee.batch.Export.table.toDrive(\n",
    "  collection=fc,\n",
    "  description='Accuracy_Export',\n",
    "  folder='earthengine',\n",
    "  fileNamePrefix='accuracy',\n",
    "  fileFormat='CSV'\n",
    ")\n",
    "\n",
    "myTask.start()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d69a3c58-198f-49c1-9b7d-d515b7d9e5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8068e8422da746fb8dce4708871e2bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "s2 = ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
    "basin = ee.FeatureCollection(\"WWF/HydroSHEDS/v1/Basins/hybas_7\")\n",
    "gcp = ee.FeatureCollection(\"users/ujavalgandhi/e2e/arkavathy_gcps\")\n",
    "alos = ee.Image(\"JAXA/ALOS/AW3D30/V2_2\")\n",
    "\n",
    "arkavathy = basin.filter(ee.Filter.eq('HYBAS_ID', 4071139640))\n",
    "boundary = arkavathy.geometry()\n",
    "rgbVis = {\n",
    "  'min': 0.0,\n",
    "  'max': 3000,\n",
    "  'bands': ['B4', 'B3', 'B2'],\n",
    "}\n",
    "# Function to remove cloud and snow pixels from Sentinel-2 SR image\n",
    "\n",
    "def maskCloudAndShadowsSR(image):\n",
    "    cloudProb = image.select('MSK_CLDPRB')\n",
    "    snowProb = image.select('MSK_SNWPRB')\n",
    "    cloud = cloudProb.lt(10)\n",
    "    scl = image.select('SCL')\n",
    "    shadow = scl.eq(3); # 3 = cloud shadow\n",
    "    cirrus = scl.eq(10); # 10 = cirrus\n",
    "    # Cloud probability less than 10% or cloud shadow classification\n",
    "    mask = cloud.And(cirrus.neq(1)).And(shadow.neq(1))\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "filtered = s2 \\\n",
    ".filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\\n",
    "  .filter(ee.Filter.date('2019-01-01', '2020-01-01')) \\\n",
    "  .filter(ee.Filter.bounds(boundary)) \\\n",
    "  .map(maskCloudAndShadowsSR) \\\n",
    "  .select('B.*')\n",
    "\n",
    "composite = filtered.median().clip(boundary)\n",
    "\n",
    "def addIndices(image):\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename(['ndvi'])\n",
    "    ndbi = image.normalizedDifference(['B11', 'B8']).rename(['ndbi'])\n",
    "    mndwi = image.normalizedDifference(['B3', 'B11']).rename(['mndwi'])\n",
    "    bsi = image.expression(\n",
    "      '(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) ', {\n",
    "        'X': image.select('B11'), #swir1\n",
    "        'Y': image.select('B4'),  #red\n",
    "        'A': image.select('B8'), # nir\n",
    "        'B': image.select('B2'), # blue\n",
    "    }).rename('bsi')\n",
    "    return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi)\n",
    "\n",
    "composite = addIndices(composite)\n",
    "\n",
    "visParams = {'bands': ['B4',  'B3',  'B2'], 'min': 0, 'max': 3000, 'gamma': 1.2}\n",
    "Map.addLayer(composite, visParams, 'RGB')\n",
    "\n",
    "# Normalize the image\n",
    "\n",
    "# Machine learning algorithms work best on images when all features have\n",
    "# the same range\n",
    "\n",
    "# Function to Normalize Image\n",
    "# Pixel Values should be between 0 and 1\n",
    "# Formula is (x - xmin) / (xmax - xmin)\n",
    "#**************************************************************************\n",
    "def normalize(image):\n",
    "    bandNames = image.bandNames()\n",
    "    # Compute min and max of the image\n",
    "    minDict = image.reduceRegion(\n",
    "        reducer=ee.Reducer.min(),\n",
    "        geometry=boundary,\n",
    "        scale=20,\n",
    "        maxPixels=1e9,\n",
    "        bestEffort=True,\n",
    "        tileScale=16\n",
    "    )\n",
    "    maxDict = image.reduceRegion(\n",
    "        reducer=ee.Reducer.max(),\n",
    "        geometry=boundary,\n",
    "        scale=20,\n",
    "        maxPixels=1e9,\n",
    "        bestEffort=True,\n",
    "        tileScale=16\n",
    "    )\n",
    "    mins = ee.Image.constant(minDict.values(bandNames))\n",
    "    maxs = ee.Image.constant(maxDict.values(bandNames))\n",
    "\n",
    "    normalized = image.subtract(mins).divide(maxs.subtract(mins))\n",
    "    return normalized\n",
    "\n",
    "composite = normalize(composite)\n",
    "# Add a random column and split the GCPs into training and validation set\n",
    "gcp = gcp.randomColumn()\n",
    "\n",
    "# This being a simpler classification, we take 60% points\n",
    "# for validation. Normal recommended ratio is\n",
    "# 70% training, 30% validation\n",
    "trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6))\n",
    "validationGcp = gcp.filter(ee.Filter.gte('random', 0.6))\n",
    "Map.addLayer(validationGcp)\n",
    "# Overlay the point on the image to get training data.\n",
    "training = composite.sampleRegions(\n",
    "  collection=trainingGcp, properties=['landcover'], scale=10, tileScale=16)\n",
    "\n",
    "# Train a classifier.\n",
    "\n",
    "classifier = ee.Classifier.smileRandomForest(50).train(\n",
    "  features=training, classProperty='landcover', inputProperties=composite.bandNames())\n",
    "\n",
    "# Classify the image.\n",
    "classified = composite.classify(classifier)\n",
    "\n",
    "Map.addLayer(classified, {'min': 0, 'max': 3, 'palette': ['gray', 'brown', 'blue', 'green']}, '2019')\n",
    "\n",
    "# Exercise \n",
    "\n",
    "# Use the Export.image.toAsset() function to export the \n",
    "# classified image as a Earth Engine Asset.\n",
    "\n",
    "# This will allows you to import the classified image in another script\n",
    "# without running the whole classification workflow.\n",
    "\n",
    "# Hint: For images with discrete pixel values, we must set the\n",
    "# pyramidingPolicy to 'mode'.\n",
    "# The pyramidingPolicy parameter should a dictionary specifying\n",
    "# the policy for each band. A simpler way to specify it for all\n",
    "# bands is to use {'.default': 'mode'}\n",
    "\n",
    "#**************************************************************************\n",
    "# Exporting Results\n",
    "#**************************************************************************\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99242cef-2c24-4a71-8876-a829cf0c1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myTask = ee.batch.Export.image.toAsset(\n",
    "    image=classified,\n",
    "    description='classified_Image_Ex',\n",
    "    assetId='users/jordandaleyco/training/classified_img_ex',\n",
    "    region=boundary,\n",
    "    scale=10,\n",
    "    maxPixels=1e10,\n",
    "    pyramidingPolicy={'.default': 'mode'}\n",
    ")\n",
    "myTask.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67402a0d-c627-4db5-8346-12219f856073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
